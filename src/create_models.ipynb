{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 11:53:06.467845: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-28 11:53:06.521738: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-28 11:53:06.521775: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-28 11:53:06.523295: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-28 11:53:06.532589: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-28 11:53:08.873648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tflite(model, input_size, n):\n",
    "    def representative_dataset():\n",
    "        for _ in range(100):\n",
    "            yield [tf.random.normal([1, *input_size])]\n",
    "\n",
    "    quantizer = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    quantizer.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    quantizer.representative_dataset = representative_dataset\n",
    "    quantizer.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    quantizer.inference_input_type = tf.uint8  # or tf.uint8\n",
    "    quantizer.inference_output_type = tf.uint8  # or tf.uint8\n",
    "    \n",
    "    tflite_quant_model = quantizer.convert()\n",
    "\n",
    "    # Save the TFLite model to a file\n",
    "    with open(f\"models/conv2/TPU_CNN2_{n}.tflite\", \"wb\") as f:\n",
    "        f.write(tflite_quant_model)\n",
    "    print(\"saved tf lite model\")\n",
    "    return tflite_quant_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " depthwise_conv2d_6 (Depthw  (None, 124, 124, 32)      320       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 122, 122, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 61, 61, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 59, 59, 64)        36928     \n",
      "                                                                 \n",
      " depthwise_conv2d_7 (Depthw  (None, 57, 57, 64)        640       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 55, 55, 128)       73856     \n",
      "                                                                 \n",
      " global_average_pooling2d_3  (None, 128)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264138 (1.01 MB)\n",
      "Trainable params: 264138 (1.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# figure out intermediete output sizes\n",
    "from architectures import conv2\n",
    "model = conv2()\n",
    "model.build((None, 128, 128, 3))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpugwfogxl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpugwfogxl/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 11:58:30.013599: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 11:58:30.013633: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 11:58:30.013845: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpugwfogxl\n",
      "2024-04-28 11:58:30.016287: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 11:58:30.016308: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpugwfogxl\n",
      "2024-04-28 11:58:30.021818: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 11:58:30.067741: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpugwfogxl\n",
      "2024-04-28 11:58:30.084424: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 70579 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 29, % non-converted = 44.83 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 2)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4_67rcls/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4_67rcls/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 11:58:37.036722: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 11:58:37.036758: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 11:58:37.037022: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp4_67rcls\n",
      "2024-04-28 11:58:37.038764: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 11:58:37.038779: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp4_67rcls\n",
      "2024-04-28 11:58:37.042940: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 11:58:37.078718: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp4_67rcls\n",
      "2024-04-28 11:58:37.090385: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 53361 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 21, % non-converted = 42.86 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7_5p0a9u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7_5p0a9u/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 11:58:40.350763: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 11:58:40.350791: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 11:58:40.351036: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp7_5p0a9u\n",
      "2024-04-28 11:58:40.352211: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 11:58:40.352226: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp7_5p0a9u\n",
      "2024-04-28 11:58:40.354500: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 11:58:40.374973: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp7_5p0a9u\n",
      "2024-04-28 11:58:40.382324: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 31287 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 5, Total Ops 12, % non-converted = 41.67 %\n",
      " * 5 ARITH ops\n",
      "\n",
      "- arith.constant:    5 occurrences  (f32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpg6evwuwa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpg6evwuwa/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 11:58:45.045929: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 11:58:45.045958: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 11:58:45.046202: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpg6evwuwa\n",
      "2024-04-28 11:58:45.047079: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 11:58:45.047095: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpg6evwuwa\n",
      "2024-04-28 11:58:45.049101: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 11:58:45.070766: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpg6evwuwa\n",
      "2024-04-28 11:58:45.078333: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 32130 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 3, Total Ops 11, % non-converted = 27.27 %\n",
      " * 3 ARITH ops\n",
      "\n",
      "- arith.constant:    3 occurrences  (f32: 3)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpe4ew4e93/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe4ew4e93/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 11:58:46.064305: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 11:58:46.064333: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 11:58:46.064584: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpe4ew4e93\n",
      "2024-04-28 11:58:46.066170: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 11:58:46.066185: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpe4ew4e93\n",
      "2024-04-28 11:58:46.069759: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 11:58:46.101835: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpe4ew4e93\n",
      "2024-04-28 11:58:46.115194: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 50609 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 10, Total Ops 21, % non-converted = 47.62 %\n",
      " * 10 ARITH ops\n",
      "\n",
      "- arith.constant:   10 occurrences  (f32: 9, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpfshcinqs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfshcinqs/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 11:58:52.008529: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 11:58:52.008561: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 11:58:52.008772: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpfshcinqs\n",
      "2024-04-28 11:58:52.009412: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 11:58:52.009425: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpfshcinqs\n",
      "2024-04-28 11:58:52.011194: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 11:58:52.027268: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpfshcinqs\n",
      "2024-04-28 11:58:52.033409: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 24637 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 2, Total Ops 9, % non-converted = 22.22 %\n",
      " * 2 ARITH ops\n",
      "\n",
      "- arith.constant:    2 occurrences  (f32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpaixv_jje/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpaixv_jje/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 11:58:53.521248: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 11:58:53.521278: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 11:58:53.521471: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpaixv_jje\n",
      "2024-04-28 11:58:53.524304: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 11:58:53.524324: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpaixv_jje\n",
      "2024-04-28 11:58:53.529710: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 11:58:53.570826: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpaixv_jje\n",
      "2024-04-28 11:58:53.585953: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 64481 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 11, Total Ops 24, % non-converted = 45.83 %\n",
      " * 11 ARITH ops\n",
      "\n",
      "- arith.constant:   11 occurrences  (f32: 10, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "src = [\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2))\n",
    "    ],  \n",
    "    [\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.GlobalAveragePooling2D()\n",
    "    ],  \n",
    "    [\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2)\n",
    "    ],\n",
    "    [\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    "]\n",
    "input_shapes = [(None,128,128,3), (None, 61, 61, 64), (None,128, ), (None,512,)]\n",
    "for i in range(0,4):\n",
    "    a= []\n",
    "    b = []\n",
    "    for layer_group in src[i:]:\n",
    "        a.extend(layer_group)\n",
    "    if a:\n",
    "        a = tf.keras.Sequential(a)\n",
    "        a.build(input_shapes[i])\n",
    "        a.save(f\"models/conv2/GPU_CNN2_{i+4}.keras\")\n",
    "        convert_to_tflite(a, input_shapes[i][1:], i)\n",
    "    \n",
    "    for layer_group in src[:i]:\n",
    "        b.extend(layer_group)\n",
    "    if b:\n",
    "        b = tf.keras.Sequential(b)\n",
    "        b.build((None, 128, 128, 3))\n",
    "        b.save(f\"models/conv2/GPU_CNN2_{i}.keras\")\n",
    "        convert_to_tflite(b, (128,128,3), i+4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
